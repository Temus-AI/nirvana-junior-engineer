{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load vllm class, check CUDA support and GPU RAM size\n",
      ":: Sending warmup message to initialize the server ...\n",
      ":: Server initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "from methods.llm import get_vllm_endpoint_func, get_claude_response\n",
    "get_endpoint_response = get_vllm_endpoint_func(\"\", \"ppas13gg82lsdh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.2.59-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 (from langgraph)\n",
      "  Downloading langchain_core-0.3.24-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.43-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/shah.mahir/.local/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.7.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.11.0)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph)\n",
      "  Downloading msgpack-1.1.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.27.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.12)\n",
      "Requirement already satisfied: anyio in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.2.0)\n",
      "Requirement already satisfied: certifi in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.2)\n",
      "Requirement already satisfied: idna in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.32.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.2.2)\n",
      "Downloading langgraph-0.2.59-py3-none-any.whl (135 kB)\n",
      "Downloading langchain_core-0.3.24-py3-none-any.whl (410 kB)\n",
      "Downloading langgraph_checkpoint-2.0.8-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_sdk-0.1.43-py3-none-any.whl (31 kB)\n",
      "Downloading msgpack-1.1.0-cp312-cp312-macosx_10_9_x86_64.whl (85 kB)\n",
      "Installing collected packages: msgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.21\n",
      "    Uninstalling langchain-core-0.3.21:\n",
      "      Successfully uninstalled langchain-core-0.3.21\n",
      "Successfully installed langchain-core-0.3.24 langgraph-0.2.59 langgraph-checkpoint-2.0.8 langgraph-sdk-0.1.43 msgpack-1.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping links\n",
      "Choosing and preprocessing links\n",
      "Classifying links and extracting nodes\n",
      "Here's the complete code as a function:\n",
      "\n",
      "```python\n",
      "from typing import Annotated, Literal, TypedDict\n",
      "from langchain_core.messages import HumanMessage\n",
      "from langchain_anthropic import ChatAnthropic\n",
      "from langchain_core.tools import tool\n",
      "from langgraph.checkpoint.memory import MemorySaver\n",
      "from langgraph.graph import END, START, StateGraph, MessagesState\n",
      "from langgraph.prebuilt import ToolNode\n",
      "\n",
      "def create_weather_agent(anthropic_api_key: str):\n",
      "    @tool\n",
      "    def search(query: str):\n",
      "        \"\"\"Call to surf the web.\"\"\"\n",
      "        if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
      "            return \"It's 60 degrees and foggy.\"\n",
      "        return \"It's 90 degrees and sunny.\"\n",
      "\n",
      "    tools = [search]\n",
      "    tool_node = ToolNode(tools)\n",
      "    model = ChatAnthropic(api_key=anthropic_api_key, model=\"claude-3-5-sonnet-20240620\", temperature=0).bind_tools(tools)\n",
      "\n",
      "    def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
      "        messages = state['messages']\n",
      "        last_message = messages[-1]\n",
      "        return \"tools\" if last_message.tool_calls else END\n",
      "\n",
      "    def call_model(state: MessagesState):\n",
      "        messages = state['messages']\n",
      "        response = model.invoke(messages)\n",
      "        return {\"messages\": [response]}\n",
      "\n",
      "    workflow = StateGraph(MessagesState)\n",
      "    workflow.add_node(\"agent\", call_model)\n",
      "    workflow.add_node(\"tools\", tool_node)\n",
      "    workflow.add_edge(START, \"agent\")\n",
      "    workflow.add_conditional_edges(\"agent\", should_continue)\n",
      "    workflow.add_edge(\"tools\", 'agent')\n",
      "    \n",
      "    checkpointer = MemorySaver()\n",
      "    app = workflow.compile(checkpointer=checkpointer)\n",
      "    \n",
      "    return app\n",
      "```\n",
      "\n",
      "```json\n",
      "{\n",
      "\"nodes\": [\n",
      "    {\n",
      "    \"task\": \"Create an AI agent that can search for and respond to weather-related queries while maintaining conversation context\",\n",
      "    \"name\": \"weather_agent\",\n",
      "    \"inputs\": [\"anthropic_api_key\"],\n",
      "    \"input_types\": [\"str\"],\n",
      "    \"outputs\": [\"agent_app\"],\n",
      "    \"output_types\": [\"Runnable\"],\n",
      "    \"target\": \"Create a stateful conversational agent that can process weather queries and maintain context\",\n",
      "    \"mode\": \"CODE\",\n",
      "    \"tests\": [\n",
      "        {\n",
      "            \"input\": {\"anthropic_api_key\": \"sk-xxx\"},\n",
      "            \"output\": {\n",
      "                \"messages\": [\n",
      "                    {\n",
      "                        \"content\": \"Based on the search results, I can tell you that the current weather in San Francisco is: Temperature: 60 degrees Fahrenheit Conditions: Foggy\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"metric_map\": {\n",
      "        \"response_time\": \"lambda x, y: isinstance(x, (int, float)) and x > 0\",\n",
      "        \"message_content\": \"lambda x, y: isinstance(x, str) and len(x) > 0\"\n",
      "    },\n",
      "    \"reasoning\": \"The code implements a stateful graph-based agent using LangGraph that can process weather queries by combining LLM capabilities with a search tool, while maintaining conversation context through a memory system, utilizing Claude 3 for intelligent responses and implementing a cycle between agent decision-making and tool usage.\"\n",
      "    }\n",
      "]}\n",
      "```\n",
      "Based on the documentation, I'll create nodes focusing on LangGraph's core functionalities. Here's a JSON representation of reusable nodes:\n",
      "\n",
      "```json\n",
      "{\n",
      "\"nodes\": [\n",
      "    {\n",
      "        \"task\": \"Implements a multi-agent conversation system where agents take turns discussing a topic, with persistence and memory capabilities. Each agent maintains its own state and can reference previous messages in the conversation.\",\n",
      "        \"name\": \"multi_agent_conversation\",\n",
      "        \"inputs\": [\"initial_topic\", \"num_agents\", \"conversation_history\"],\n",
      "        \"input_types\": [\"str\", \"int\", \"list\"],\n",
      "        \"outputs\": [\"conversation_result\", \"agent_states\", \"time_taken\"],\n",
      "        \"output_types\": [\"dict\", \"dict\", \"float\"],\n",
      "        \"target\": \"Create a persistent multi-agent conversation system with memory\",\n",
      "        \"mode\": \"CODE\",\n",
      "        \"tests\": [{\n",
      "            \"input\": {\n",
      "                \"initial_topic\": \"climate change\",\n",
      "                \"num_agents\": 3,\n",
      "                \"conversation_history\": []\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"conversation_result\": {\n",
      "                    \"messages\": [\"Let's discuss climate change\", \"I believe renewable energy is key\"],\n",
      "                    \"final_topic\": \"renewable energy solutions\"\n",
      "                },\n",
      "                \"agent_states\": {\n",
      "                    \"agent_1\": {\"memory\": [\"discussed climate impact\"]},\n",
      "                    \"agent_2\": {\"memory\": [\"proposed solutions\"]}\n",
      "                },\n",
      "                \"time_taken\": 2.5\n",
      "            }\n",
      "        }],\n",
      "        \"metric_map\": {\n",
      "            \"time_taken\": \"lambda x, y: x > 0\"\n",
      "        },\n",
      "        \"relevant_docs\": \"Using LangGraph's multi-agent system:\\n1. Import required components:\\nfrom langgraph.graph import StateGraph, END\\nfrom langgraph.prebuilt.agents import Agent\\n\\n2. Create agents:\\nagent = Agent(llm=your_llm, tools=tools)\\n\\n3. Define state schema:\\nclass ConversationState(TypedDict):\\n    messages: list[str]\\n    next_agent: str\\n\\n4. Create graph:\\ngraph = StateGraph(ConversationState)\\n\\n5. Add nodes:\\ngraph.add_node('agent_1', agent_1_fn)\\ngraph.add_node('agent_2', agent_2_fn)\\n\\n6. Connect nodes:\\ngraph.add_edge('agent_1', 'agent_2')\\n\\nKey features:\\n- StateGraph maintains conversation state\\n- Agents can access shared memory\\n- Support for conditional routing between agents\"\n",
      "    },\n",
      "    {\n",
      "        \"task\": \"Implements a human-in-the-loop review system that processes documents, pauses for human feedback at specified breakpoints, and incorporates the feedback to improve document processing. Includes capability to save state and resume processing.\",\n",
      "        \"name\": \"human_review_processor\",\n",
      "        \"inputs\": [\"document_text\", \"review_points\", \"previous_feedback\"],\n",
      "        \"input_types\": [\"str\", \"list\", \"dict\"],\n",
      "        \"outputs\": [\"processed_document\", \"review_state\"],\n",
      "        \"output_types\": [\"str\", \"dict\"],\n",
      "        \"target\": \"Create an interactive document processing system with human feedback\",\n",
      "        \"mode\": \"CODE\",\n",
      "        \"tests\": [{\n",
      "            \"input\": {\n",
      "                \"document_text\": \"This is a sample document requiring review\",\n",
      "                \"review_points\": [\"clarity\", \"accuracy\"],\n",
      "                \"previous_feedback\": {\"clarity\": \"needs improvement\"}\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"processed_document\": \"This is an improved document after review\",\n",
      "                \"review_state\": {\"status\": \"completed\", \"feedback_incorporated\": true}\n",
      "            }\n",
      "        }],\n",
      "        \"metric_map\": null,\n",
      "        \"relevant_docs\": \"Implementing human-in-the-loop with LangGraph:\\n1. Import components:\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.checkpoint import Checkpoint\\n\\n2. Create checkpoint handler:\\ncheckpoint = Checkpoint(dir='./checkpoints')\\n\\n3. Define breakpoint:\\ndef human_review_point(state):\\n    return {'requires_review': True, 'current_state': state}\\n\\n4. Setup graph with checkpoint:\\ngraph = StateGraph()\\ngraph.add_node('process', process_fn)\\ngraph.add_node('review', human_review_point)\\n\\n5. Add checkpoint:\\ngraph.add_checkpoint(checkpoint)\\n\\nCheckpoint methods:\\n- save_checkpoint(state)\\n- load_checkpoint(checkpoint_id)\\n- list_checkpoints()\\n\\nBreakpoint features:\\n- Pause execution at defined points\\n- Save current state\\n- Resume processing after feedback\\n- Access to full state history\"\n",
      "    }\n",
      "]\n",
      "}\n",
      "```\n",
      "\n",
      "I've created two complex nodes that showcase key LangGraph features:\n",
      "\n",
      "1. A multi-agent conversation system that demonstrates the use of StateGraph, agent interactions, and memory persistence.\n",
      "2. A human-in-the-loop document processing system that shows how to implement breakpoints, checkpoints, and state management.\n",
      "\n",
      "Each node includes detailed documentation about how to implement the functionality using LangGraph's APIs, including import statements, class definitions, and key methods. The test cases provide realistic examples of inputs and outputs, and metric maps are included where appropriate (like for non-deterministic time measurements).\n",
      "Based on the LangGraph documentation, I'll create a JSON structure with reusable nodes focusing on agent-based workflows:\n",
      "\n",
      "```json\n",
      "{\n",
      "\"nodes\": [\n",
      "    {\n",
      "        \"task\": \"Implements a sophisticated RAG system that retrieves relevant documents, processes them through an LLM for relevance scoring, and then combines the most relevant pieces into a coherent context for the next stage of processing\",\n",
      "        \"name\": \"advanced_rag_processor\",\n",
      "        \"inputs\": [\"query\", \"document_store\", \"relevance_threshold\"],\n",
      "        \"input_types\": [\"str\", \"DocumentStore\", \"float\"],\n",
      "        \"outputs\": [\"processed_context\", \"retrieval_metadata\", \"relevance_scores\"],\n",
      "        \"output_types\": [\"str\", \"dict\", \"list[float]\"],\n",
      "        \"target\": \"Enhanced document retrieval and context preparation for LLM processing\",\n",
      "        \"mode\": \"CODE\",\n",
      "        \"tests\": [\n",
      "            {\n",
      "                \"input\": {\n",
      "                    \"query\": \"What are the benefits of LangGraph?\",\n",
      "                    \"document_store\": \"mock_store\",\n",
      "                    \"relevance_threshold\": 0.7\n",
      "                },\n",
      "                \"output\": {\n",
      "                    \"processed_context\": \"LangGraph offers controllability, persistence, and human-in-the-loop capabilities\",\n",
      "                    \"retrieval_metadata\": {\"num_docs\": 3},\n",
      "                    \"relevance_scores\": [0.85, 0.79, 0.72]\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"metric_map\": {\n",
      "            \"relevance_scores\": \"lambda x, y: all(score >= 0 and score <= 1 for score in x)\"\n",
      "        },\n",
      "        \"relevant_docs\": \"Requires LangGraph and a vector store library like ChromaDB or FAISS. \\nImport: from langgraph.graph import Graph\\nKey components:\\n- DocumentStore: Abstract base class for document storage\\n- Graph.add_node(): Adds processing node to workflow\\n- Graph.add_edge(): Connects nodes in workflow\\nExample usage:\\ngraph = Graph()\\ngraph.add_node('rag_processor', advanced_rag_processor)\\ngraph.add_edge('rag_processor', 'next_node')\\nSupports streaming via .stream() method for real-time processing\"\n",
      "    },\n",
      "    {\n",
      "        \"task\": \"Implements a stateful agent that maintains conversation history, tracks tool usage, and makes decisions about whether to use tools or respond directly. Includes error handling and recovery mechanisms\",\n",
      "        \"name\": \"stateful_agent_executor\",\n",
      "        \"inputs\": [\"user_input\", \"agent_state\", \"available_tools\"],\n",
      "        \"input_types\": [\"str\", \"dict\", \"list[Tool]\"],\n",
      "        \"outputs\": [\"response\", \"updated_state\", \"tool_calls\"],\n",
      "        \"output_types\": [\"str\", \"dict\", \"list[dict]\"],\n",
      "        \"target\": \"Managed execution of agent actions with state preservation\",\n",
      "        \"mode\": \"CODE\",\n",
      "        \"tests\": [\n",
      "            {\n",
      "                \"input\": {\n",
      "                    \"user_input\": \"Calculate 15% of 85\",\n",
      "                    \"agent_state\": {\"conversation_history\": []},\n",
      "                    \"available_tools\": [\"calculator\"]\n",
      "                },\n",
      "                \"output\": {\n",
      "                    \"response\": \"15% of 85 is 12.75\",\n",
      "                    \"updated_state\": {\"conversation_history\": [\"User asked for calculation\"]},\n",
      "                    \"tool_calls\": [{\"tool\": \"calculator\", \"input\": \"0.15 * 85\"}]\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"metric_map\": null,\n",
      "        \"relevant_docs\": \"Uses LangGraph's state management and tool calling features.\\nImport:\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.presets import Tool\\n\\nKey concepts:\\n- StateGraph: Manages graph with state\\n- Tool: Class for defining usable tools\\n- State management through dict updates\\n\\nExample initialization:\\ngraph = StateGraph()\\ndef state_manager(state):\\n    return GraphState(state)\\ngraph.set_state_manager(state_manager)\\n\\nKey methods:\\n- add_node(name, handler_func)\\n- set_entry_point(node_name)\\n- add_edge(from_node, to_node)\\n\\nSupports both synchronous and async execution\"\n",
      "    },\n",
      "    {\n",
      "        \"task\": \"Implements a human-in-the-loop review system that can pause execution, present intermediate results for review, and incorporate feedback before continuing execution\",\n",
      "        \"name\": \"human_review_controller\",\n",
      "        \"inputs\": [\"current_state\", \"checkpoint_condition\", \"review_type\"],\n",
      "        \"input_types\": [\"dict\", \"str\", \"str\"],\n",
      "        \"outputs\": [\"approved_state\", \"review_feedback\", \"continue_execution\"],\n",
      "        \"output_types\": [\"dict\", \"str\", \"bool\"],\n",
      "        \"target\": \"Human oversight and intervention in agent execution\",\n",
      "        \"mode\": \"CODE\",\n",
      "        \"tests\": [\n",
      "            {\n",
      "                \"input\": {\n",
      "                    \"current_state\": {\"progress\": \"50%\"},\n",
      "                    \"checkpoint_condition\": \"requires_review\",\n",
      "                    \"review_type\": \"manual\"\n",
      "                },\n",
      "                \"output\": {\n",
      "                    \"approved_state\": {\"progress\": \"50%\", \"reviewed\": true},\n",
      "                    \"review_feedback\": \"Approved with minor changes\",\n",
      "                    \"continue_execution\": true\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"metric_map\": null,\n",
      "        \"relevant_docs\": \"Utilizes LangGraph's persistence and human-in-the-loop capabilities.\\nImport:\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.persistence import GraphState\\n\\nKey features:\\n- Persistence layer for state preservation\\n- Checkpoint mechanism for execution pausing\\n- Review interface integration\\n\\nExample setup:\\ndef review_handler(state, condition):\\n    if condition == 'requires_review':\\n        return await_human_review(state)\\n    return state\\n\\ngraph.add_node('review', review_handler)\\n\\nSupports:\\n- Multiple review types (manual, automated)\\n- State modification during review\\n- Conditional execution paths\\n- Async review processes\"\n",
      "    }\n",
      "]\n",
      "}\n",
      "```\n",
      "\n",
      "Note: I've created complex nodes that incorporate multiple features of LangGraph, focusing on practical use cases like RAG, stateful agents, and human-in-the-loop systems. Each node includes detailed documentation and realistic test cases. The `metric_map` is used only where outputs are truly non-deterministic or require validation beyond exact matching.\n",
      "Based on the provided documentation about LangGraph, I'll create some nodes that could be useful for self-hosted deployment scenarios:\n",
      "\n",
      "```json\n",
      "{\n",
      "\"nodes\": [\n",
      "    {\n",
      "        \"task\": \"Configure and validate the self-hosted LangGraph deployment environment by checking Redis and Postgres connectivity, verifying license keys, and ensuring all required environment variables are set correctly\",\n",
      "        \"name\": \"setup_langgraph_environment\",\n",
      "        \"inputs\": [\"license_key\", \"redis_url\", \"postgres_url\", \"env_vars\"],\n",
      "        \"input_types\": [\"str\", \"str\", \"str\", \"dict\"],\n",
      "        \"outputs\": [\"validation_status\", \"error_messages\", \"connection_latency\"],\n",
      "        \"output_types\": [\"bool\", \"list\", \"float\"],\n",
      "        \"target\": \"Environment setup and validation for LangGraph self-hosted deployment\",\n",
      "        \"mode\": \"CODE\",\n",
      "        \"tests\": [{\n",
      "            \"input\": {\n",
      "                \"license_key\": \"lgp-ent-xxxxx\",\n",
      "                \"redis_url\": \"redis://localhost:6379\",\n",
      "                \"postgres_url\": \"postgresql://user:pass@localhost:5432/db\",\n",
      "                \"env_vars\": {\"LANGGRAPH_API_KEY\": \"sk-xxx\"}\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"validation_status\": true,\n",
      "                \"error_messages\": [],\n",
      "                \"connection_latency\": 0.23\n",
      "            }\n",
      "        }],\n",
      "        \"metric_map\": {\n",
      "            \"connection_latency\": \"lambda x, y: x > 0 and x < 5\"\n",
      "        },\n",
      "        \"relevant_docs\": \"To set up LangGraph self-hosted:\\n1. Import required packages:\\n   from langgraph.deployment import validate_environment\\n   from langgraph.config import Config\\n\\n2. Redis connection requires redis-py package:\\n   import redis\\n   redis_client = redis.from_url(redis_url)\\n\\n3. Postgres connection uses psycopg2:\\n   import psycopg2\\n   conn = psycopg2.connect(postgres_url)\\n\\n4. License validation format: Enterprise licenses start with 'lgp-ent-'\\n   Lite version uses LangSmith API key format 'sk-xxx'\\n\\nThe environment requires:\\n- Redis instance running (for caching and pub/sub)\\n- Postgres database (for persistence)\\n- Valid license key for Enterprise version\\n- Environment variables set including LANGGRAPH_API_KEY\"\n",
      "    },\n",
      "    {\n",
      "        \"task\": \"Build and prepare a LangGraph docker image with custom configurations, including setting up necessary dependencies, configuring environment variables, and validating the build process\",\n",
      "        \"name\": \"build_langgraph_docker\",\n",
      "        \"inputs\": [\"dockerfile_path\", \"config_path\", \"build_args\", \"target_registry\"],\n",
      "        \"input_types\": [\"str\", \"str\", \"dict\", \"str\"],\n",
      "        \"outputs\": [\"image_id\", \"build_logs\", \"image_size\"],\n",
      "        \"output_types\": [\"str\", \"list\", \"float\"],\n",
      "        \"target\": \"Docker image creation for LangGraph deployment\",\n",
      "        \"mode\": \"CODE\",\n",
      "        \"tests\": [{\n",
      "            \"input\": {\n",
      "                \"dockerfile_path\": \"./Dockerfile\",\n",
      "                \"config_path\": \"./config.yaml\",\n",
      "                \"build_args\": {\"VERSION\": \"1.0.0\"},\n",
      "                \"target_registry\": \"docker.io/myregistry\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"image_id\": \"sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n",
      "                \"build_logs\": [\"Step 1/15: FROM python:3.9\", \"Step 2/15: WORKDIR /app\"],\n",
      "                \"image_size\": 1200.5\n",
      "            }\n",
      "        }],\n",
      "        \"metric_map\": {\n",
      "            \"image_size\": \"lambda x, y: x > 0\"\n",
      "        },\n",
      "        \"relevant_docs\": \"Building LangGraph Docker images:\\n1. Use langgraph-cli:\\n   pip install langgraph-cli\\n   langgraph build --config config.yaml\\n\\n2. The config.yaml structure:\\n   version: '1.0'\\n   build:\\n     base_image: python:3.9\\n     requirements:\\n       - langgraph\\n       - redis\\n       - psycopg2-binary\\n\\n3. Docker build command structure:\\n   docker build -t langgraph-server:version \\\\\\n     --build-arg LICENSE_KEY=xxx \\\\\\n     --build-arg REDIS_URL=xxx \\\\\\n     -f Dockerfile .\\n\\nThe build process requires:\\n- Docker installed and running\\n- Valid config.yaml with all dependencies\\n- Appropriate build arguments for environment setup\\n- Access rights to target registry for push operations\"\n",
      "    }\n",
      "]\n",
      "}\n",
      "```\n",
      "\n",
      "I've created two complex nodes that would be useful in setting up a self-hosted LangGraph deployment. Each node handles multiple related tasks and includes comprehensive documentation. The first node handles environment validation and setup, while the second manages Docker image building. The test cases include realistic example values, and metric maps are provided for non-deterministic outputs like connection latency and image size.\n",
      "Here's the complete code based on the guide:\n",
      "\n",
      "```python\n",
      "from typing import Literal, Dict, Any\n",
      "from typing_extensions import TypedDict\n",
      "from langgraph.graph import StateGraph, END, START\n",
      "from langchain.tools import Tool\n",
      "\n",
      "class AgentState(TypedDict):\n",
      "    messages: list\n",
      "    next_action: str\n",
      "    action_input: str\n",
      "    tools: Dict[str, Tool]\n",
      "    current_tool: str\n",
      "\n",
      "class GraphConfig(TypedDict):\n",
      "    model_name: Literal[\"anthropic\", \"openai\"]\n",
      "\n",
      "def create_agent_graph(model_name: str = \"openai\"):\n",
      "    def call_model(state: AgentState) -> AgentState:\n",
      "        # Simulate model call\n",
      "        state[\"next_action\"] = \"continue\"\n",
      "        return state\n",
      "    \n",
      "    def should_continue(state: AgentState) -> Literal[\"continue\", \"end\"]:\n",
      "        return state[\"next_action\"]\n",
      "    \n",
      "    def tool_node(state: AgentState) -> AgentState:\n",
      "        # Simulate tool execution\n",
      "        return state\n",
      "\n",
      "    workflow = StateGraph(AgentState, config_schema=GraphConfig)\n",
      "    \n",
      "    workflow.add_node(\"agent\", call_model)\n",
      "    workflow.add_node(\"action\", tool_node)\n",
      "    workflow.add_edge(START, \"agent\")\n",
      "    workflow.add_conditional_edges(\n",
      "        \"agent\",\n",
      "        should_continue,\n",
      "        {\n",
      "            \"continue\": \"action\",\n",
      "            \"end\": END,\n",
      "        },\n",
      "    )\n",
      "    workflow.add_edge(\"action\", \"agent\")\n",
      "    \n",
      "    return workflow.compile()\n",
      "\n",
      "```\n",
      "\n",
      "```json\n",
      "{\n",
      "\"nodes\": [\n",
      "    {\n",
      "        \"task\": \"Create a LangGraph agent with a state machine workflow\",\n",
      "        \"name\": \"create_agent_graph\",\n",
      "        \"inputs\": [\"model_name\"],\n",
      "        \"input_types\": [\"str\"],\n",
      "        \"outputs\": [\"compiled_graph\"],\n",
      "        \"output_types\": [\"CompiledGraph\"],\n",
      "        \"target\": \"Create a functional agent graph that can be deployed\",\n",
      "        \"mode\": \"CODE\",\n",
      "        \"tests\": [\n",
      "            {\n",
      "                \"input\": {\"model_name\": \"openai\"},\n",
      "                \"output\": {\"compiled_graph\": \"<CompiledGraph object>\"}\n",
      "            }\n",
      "        ],\n",
      "        \"metric_map\": {\n",
      "            \"compiled_graph\": \"lambda x, y: isinstance(x, object)\"\n",
      "        },\n",
      "        \"reasoning\": \"The code implements a state machine workflow with an agent node for model calls and an action node for tool execution, using TypedDict for strict typing and conditional edges to control flow between continue/end states.\"\n",
      "    }\n",
      "]\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "\"nodes\": [\n",
      "    {\n",
      "        \"task\": \"Set up a ReAct agent with custom tools and human-in-the-loop capabilities, including checkpoint management and interruption points. This involves initializing the model, defining tools, setting up checkpointing, and configuring the agent.\",\n",
      "        \"name\": \"setup_react_agent\",\n",
      "        \"inputs\": [\"model_name\", \"tools_list\", \"interrupt_points\", \"checkpoint_id\"],\n",
      "        \"input_types\": [\"str\", \"List[Callable]\", \"List[str]\", \"str\"],\n",
      "        \"outputs\": [\"agent\", \"checkpointer\"],\n",
      "        \"output_types\": [\"ReactAgent\", \"MemorySaver\"],\n",
      "        \"target\": \"Initialize a ReAct agent with human-in-the-loop capabilities\",\n",
      "        \"mode\": \"CODE\",\n",
      "        \"tests\": [{\n",
      "            \"input\": {\n",
      "                \"model_name\": \"gpt-4\",\n",
      "                \"tools_list\": \"[get_weather]\", \n",
      "                \"interrupt_points\": \"['tools']\",\n",
      "                \"checkpoint_id\": \"42\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"agent\": \"<ReactAgent object>\",\n",
      "                \"checkpointer\": \"<MemorySaver object>\"\n",
      "            }\n",
      "        }],\n",
      "        \"metric_map\": null,\n",
      "        \"relevant_docs\": \"To set up a ReAct agent with human-in-the-loop:\\n1. Import required packages:\\n   from langgraph.prebuilt import create_react_agent\\n   from langgraph.checkpoint.memory import MemorySaver\\n   from langchain_openai import ChatOpenAI\\n2. Initialize model:\\n   model = ChatOpenAI(model='model_name', temperature=0)\\n3. Create checkpointer:\\n   memory = MemorySaver()\\n4. Create agent:\\n   graph = create_react_agent(model, tools=tools_list, interrupt_before=interrupt_points, checkpointer=memory)\\nThe create_react_agent function takes:\\n- model: LLM instance\\n- tools: List of tool functions\\n- interrupt_before: List of points to pause for human input\\n- checkpointer: Instance to manage state\\nReturns a ReAct agent that can be used with graph.stream()\"\n",
      "    },\n",
      "    {\n",
      "        \"task\": \"Process and handle human intervention in a ReAct agent's workflow, including state inspection, tool call modification, and workflow resumption. This involves getting current state, modifying tool parameters if needed, updating state, and continuing execution.\",\n",
      "        \"name\": \"handle_human_intervention\", \n",
      "        \"inputs\": [\"agent\", \"current_state\", \"modified_tool_args\", \"config\"],\n",
      "        \"input_types\": [\"ReactAgent\", \"Dict\", \"Dict\", \"Dict\"],\n",
      "        \"outputs\": [\"updated_state\", \"continuation_stream\"],\n",
      "        \"output_types\": [\"Dict\", \"Iterator\"],\n",
      "        \"target\": \"Enable human review and modification of agent actions\",\n",
      "        \"mode\": \"CODE\",\n",
      "        \"tests\": [{\n",
      "            \"input\": {\n",
      "                \"agent\": \"<ReactAgent object>\",\n",
      "                \"current_state\": \"{'messages': [<Message object>]}\",\n",
      "                \"modified_tool_args\": \"{'location': 'San Francisco'}\",\n",
      "                \"config\": \"{'thread_id': '42'}\"\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"updated_state\": \"{'messages': [<Updated Message object>]}\",\n",
      "                \"continuation_stream\": \"<Iterator object>\"\n",
      "            }\n",
      "        }],\n",
      "        \"metric_map\": null,\n",
      "        \"relevant_docs\": \"To handle human intervention in ReAct agent:\\n1. Get current state:\\n   state = graph.get_state(config)\\n2. Extract last message:\\n   last_message = state.values['messages'][-1]\\n3. Modify tool arguments:\\n   last_message.tool_calls[0]['args'] = modified_args\\n4. Update state:\\n   graph.update_state(config, {'messages': [last_message]})\\n5. Resume execution:\\n   continuation = graph.stream(None, config, stream_mode='values')\\nKey concepts:\\n- State contains messages and current execution point\\n- Tool calls can be modified before execution\\n- Need to update state before resuming\\n- Use None as input when resuming interrupted flow\\nThe config dict needs thread_id for checkpointing\"\n",
      "    }\n",
      "]\n",
      "}\n",
      "```\n",
      "Based on the LangGraph Platform documentation, I'll create some useful nodes that could be implemented in a production environment:\n",
      "\n",
      "```json\n",
      "{\n",
      "\"nodes\": [\n",
      "    {\n",
      "        \"task\": \"Handles background agent processing with heartbeat monitoring and timeout management. This node initiates a long-running agent task, sets up heartbeat signals to prevent connection timeouts, and manages the background processing state. It includes timeout handling and status updates.\",\n",
      "        \"name\": \"background_agent_processor\",\n",
      "        \"inputs\": [\"agent_config\", \"max_runtime\", \"heartbeat_interval\"],\n",
      "        \"input_types\": [\"dict\", \"int\", \"int\"],\n",
      "        \"outputs\": [\"run_id\", \"status\", \"processing_time\"],\n",
      "        \"output_types\": [\"str\", \"str\", \"float\"],\n",
      "        \"target\": \"Enable long-running agent tasks with proper monitoring and timeout handling\",\n",
      "        \"mode\": \"CODE\",\n",
      "        \"tests\": [{\n",
      "            \"input\": {\n",
      "                \"agent_config\": {\"model\": \"gpt-4\", \"max_steps\": 10},\n",
      "                \"max_runtime\": 3600,\n",
      "                \"heartbeat_interval\": 30\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"run_id\": \"bg_run_123\",\n",
      "                \"status\": \"running\",\n",
      "                \"processing_time\": 0.45\n",
      "            }\n",
      "        }],\n",
      "        \"metric_map\": {\n",
      "            \"processing_time\": \"lambda x, y: x > 0 and x < 3600\"\n",
      "        },\n",
      "        \"relevant_docs\": \"Using LangGraph Server for background processing:\\n1. Import required components:\\nfrom langgraph.server import LangGraphServer\\nfrom langgraph.server.background import BackgroundTaskManager\\n\\n2. Server initialization:\\nserver = LangGraphServer()\\ntask_manager = BackgroundTaskManager()\\n\\n3. Key methods:\\n- start_background_run(agent_config: dict) -> str: Initiates background processing\\n- get_run_status(run_id: str) -> str: Checks current status\\n- setup_heartbeat(interval: int): Configures heartbeat signal\\n\\nThe heartbeat_interval should be less than any server timeout settings.\\nTypical usage:\\ntask_id = server.start_background_run(config)\\nstatus = server.get_run_status(task_id)\"\n",
      "    },\n",
      "    {\n",
      "        \"task\": \"Implements a robust streaming response handler with double-text protection and burst request management. This node manages real-time user interactions, handles multiple rapid requests, and ensures proper message ordering while preventing duplicate processing.\",\n",
      "        \"name\": \"stream_request_handler\",\n",
      "        \"inputs\": [\"user_message\", \"session_id\", \"buffer_time\"],\n",
      "        \"input_types\": [\"str\", \"str\", \"float\"],\n",
      "        \"outputs\": [\"stream_response\", \"message_status\", \"queue_position\"],\n",
      "        \"output_types\": [\"generator\", \"str\", \"int\"],\n",
      "        \"target\": \"Handle real-time streaming responses with proper request management\",\n",
      "        \"mode\": \"CODE\",\n",
      "        \"tests\": [{\n",
      "            \"input\": {\n",
      "                \"user_message\": \"Hello, how are you?\",\n",
      "                \"session_id\": \"sess_123\",\n",
      "                \"buffer_time\": 0.5\n",
      "            },\n",
      "            \"output\": {\n",
      "                \"stream_response\": \"<generator object>\",\n",
      "                \"message_status\": \"processing\",\n",
      "                \"queue_position\": 1\n",
      "            }\n",
      "        }],\n",
      "        \"metric_map\": {\n",
      "            \"queue_position\": \"lambda x, y: x >= 0\"\n",
      "        },\n",
      "        \"relevant_docs\": \"LangGraph Server Streaming Support:\\n1. Import streaming components:\\nfrom langgraph.server.streaming import StreamManager\\nfrom langgraph.server.queue import RequestQueue\\n\\n2. Initialize components:\\nstream_manager = StreamManager()\\nrequest_queue = RequestQueue()\\n\\n3. Key methods:\\n- handle_stream(message: str, session_id: str) -> AsyncGenerator\\n- add_to_queue(request: dict) -> int\\n- set_buffer_window(time: float)\\n\\nExample usage:\\nasync def process_stream(message, session):\\n    stream = await stream_manager.handle_stream(message, session)\\n    async for token in stream:\\n        yield token\\n\\nThe buffer_time parameter helps prevent double-texting by grouping messages within the specified window.\"\n",
      "    }\n",
      "]\n",
      "}\n",
      "```\n",
      "\n",
      "These nodes represent complex functionalities that would be commonly needed in production deployments of LangGraph applications. Each node includes detailed documentation and realistic test cases, with metric maps for non-deterministic outputs. The tasks are non-trivial and incorporate multiple features of the LangGraph Platform.\n",
      "\n",
      "I've focused on making the `relevant_docs` section particularly detailed, including import statements, method signatures, and usage examples. The nodes handle complex scenarios like background processing and streaming responses, which are mentioned in the documentation as important features of the platform.\n",
      "     :: Query time: 4.07s\n",
      "ERROR PARSING CODE\n",
      "     :: Evolution time: 15.23s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        2\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 4.07s\n",
      "     :: Evolution time: 15.23s\n",
      "     :: Evaluation time: 2.59s\n",
      "     :: Total time: 21.89s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langgraph.prebuilt.agents'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langgraph.prebuilt.agents'\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 4.08s\n",
      "ERROR PARSING CODE\n",
      "     :: Evolution time: 12.11s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        2\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 4.08s\n",
      "     :: Evolution time: 12.11s\n",
      "     :: Evaluation time: 1.11s\n",
      "     :: Total time: 17.31s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "cannot import name 'Checkpoint' from 'langgraph.checkpoint' (unknown location)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "cannot import name 'Checkpoint' from 'langgraph.checkpoint' (unknown location)\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 3.88s\n",
      "     :: Evolution time: 18.92s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        3\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 3.88s\n",
      "     :: Evolution time: 18.92s\n",
      "     :: Evaluation time: 1.21s\n",
      "     :: Total time: 24.01s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'anndata'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'criteria'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 2: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "name 'DocumentStore' is not defined\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 3.67s\n",
      "ERROR PARSING CODE\n",
      "     :: Evolution time: 26.50s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        2\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 3.67s\n",
      "     :: Evolution time: 26.50s\n",
      "     :: Evaluation time: 1.07s\n",
      "     :: Total time: 31.24s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "cannot import name 'GraphState' from 'langgraph.graph' (/Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages/langgraph/graph/__init__.py)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langgraph.presets'\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 3.53s\n",
      "     :: Evolution time: 12.73s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        3\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 3.53s\n",
      "     :: Evolution time: 12.73s\n",
      "     :: Evaluation time: 0.94s\n",
      "     :: Total time: 17.20s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "name 'GraphState' is not defined\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langgraph.persistence'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 2: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "isinstance() arg 2 must be a type, a tuple of types, or a union\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 3.98s\n",
      "     :: Evolution time: 11.57s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        3\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 3.98s\n",
      "     :: Evolution time: 11.57s\n",
      "     :: Evaluation time: 0.95s\n",
      "     :: Total time: 16.51s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langgraph.config'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langgraph.config'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 2: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langgraph.config'\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 3.59s\n",
      "ERROR PARSING CODE\n",
      "     :: Evolution time: 9.81s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        2\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 3.59s\n",
      "     :: Evolution time: 9.81s\n",
      "     :: Evaluation time: 1.38s\n",
      "     :: Total time: 14.79s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'docker'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "name 'subprocess' is not defined\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 3.86s\n",
      "ERROR PARSING CODE\n",
      "     :: Evolution time: 7.40s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        2\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 3.86s\n",
      "     :: Evolution time: 7.40s\n",
      "     :: Evaluation time: 0.54s\n",
      "     :: Total time: 11.80s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langchain_openai'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langchain_openai'\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 3.81s\n",
      "     :: Evolution time: 6.05s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        3\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 3.81s\n",
      "     :: Evolution time: 6.05s\n",
      "     :: Evaluation time: 1.13s\n",
      "     :: Total time: 11.00s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "name 'ReactAgent' is not defined\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "'str' object has no attribute 'get_state'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 2: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "name 'ReactAgent' is not defined\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 3.86s\n",
      "     :: Evolution time: 8.75s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        3\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 3.86s\n",
      "     :: Evolution time: 8.75s\n",
      "     :: Evaluation time: 0.99s\n",
      "     :: Total time: 13.60s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langgraph.server'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langgraph.server'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 2: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "name 'BackgroundTaskManager' is not defined\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 4.07s\n",
      "     :: Evolution time: 16.99s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        3\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 4.07s\n",
      "     :: Evolution time: 16.99s\n",
      "     :: Evaluation time: 1.07s\n",
      "     :: Total time: 22.14s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "name 'request_queue' is not defined\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langgraph.server'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 2: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Function 'stream_request_handler' not found in generated code\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on meta_api fuctionals\n",
    "from methods.meta_api import nodes_from_api\n",
    "api_name = \"langgraph\"\n",
    "doc_nodes, guide_nodes = nodes_from_api(api_name, fast_response=get_endpoint_response, slow_response=get_claude_response, max_links=2) # Takes 2 mins to scrape langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping links\n",
      "Choosing and preprocessing links\n",
      "Classifying links and extracting nodes\n",
      "     :: Query time: 4.51s\n",
      "ERROR PARSING CODE\n",
      "     :: Evolution time: 16.33s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        2\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 4.51s\n",
      "     :: Evolution time: 16.33s\n",
      "     :: Evaluation time: 0.99s\n",
      "     :: Total time: 21.83s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langchain.anthropic'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "No module named 'langchain_anthropic'\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 4.58s\n",
      "     :: Evolution time: 11.41s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        3\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 4.58s\n",
      "     :: Evolution time: 11.41s\n",
      "     :: Evaluation time: 1.11s\n",
      "     :: Total time: 17.10s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "name 'MemorySaver' is not defined\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "name 'MemorySaver' is not defined\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 2: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "name 'Tuple' is not defined\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 3.92s\n",
      "ERROR PARSING CODE\n",
      "ERROR PARSING CODE\n",
      "     :: Evolution time: 17.78s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        1\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 3.92s\n",
      "     :: Evolution time: 17.78s\n",
      "     :: Evaluation time: 1.04s\n",
      "     :: Total time: 22.73s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "cannot import name 'make_agent' from 'langchain.agents' (/Users/shah.mahir/opt/anaconda3/lib/python3.12/site-packages/langchain/agents/__init__.py)\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 4.18s\n",
      "     :: Evolution time: 7.19s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        3\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 4.18s\n",
      "     :: Evolution time: 7.19s\n",
      "     :: Evaluation time: 1.12s\n",
      "     :: Total time: 12.49s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "cannot import name 'GraphCheckpoint' from 'langgraph.checkpoint' (unknown location)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "cannot import name 'GraphCheckpoint' from 'langgraph.checkpoint' (unknown location)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 2: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "cannot import name 'GraphCheckpoint' from 'langgraph.checkpoint' (unknown location)\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 4.05s\n",
      "     :: Evolution time: 10.91s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        3\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 4.05s\n",
      "     :: Evolution time: 10.91s\n",
      "     :: Evaluation time: 1.05s\n",
      "     :: Total time: 16.01s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "'rules'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "'rules'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 2: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "'rules'\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 4.96s\n",
      "ERROR PARSING CODE\n",
      "ERROR PARSING CODE\n",
      "     :: Evolution time: 17.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concurrent Execution of 1 Node functions to generate prompts ...: 100%|‚ñà| 1/1 [0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        1\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 4.96s\n",
      "     :: Evolution time: 17.49s\n",
      "     :: Evaluation time: 1.90s\n",
      "     :: Total time: 24.35s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Must provide state_schema or input and output\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 4.04s\n",
      "     :: Evolution time: 9.68s\n",
      "\n",
      "Code 0 outputs:\n",
      "Test 0: {'updated_state': ({'history': [{'event': 'tool_call'}, {'event': 'tool_call'}, ''], 'summary': '', 'pruned_items': []}, '', [])}\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 1.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.50\n",
      "  üîÑ Compiled solutions:        3\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 4.04s\n",
      "     :: Evolution time: 9.68s\n",
      "     :: Evaluation time: 1.62s\n",
      "     :: Total time: 15.34s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 50.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "Input: {'current_state': {'history': [{'event': 'tool_call'}, {'event': 'tool_call'}, ''], 'summary': '', 'pruned_items': []}, 'new_information': {'event': 'tool_call'}, 'memory_config': {'max_items': 10}}, prediction is not aligned with expected output, Expected: {'updated_state': {'history': [{'event': 'tool_call'}]}, 'summary': 'Added new tool call event', 'pruned_items': []} Predicted: {'updated_state': ({'history': [{'event': 'tool_call'}, {'event': 'tool_call'}, ''], 'summary': '', 'pruned_items': []}, '', [])}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 1: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "'context'\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 2: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "cannot access local variable 'pruned_items' where it is not associated with a value\n",
      "================================================================================\n",
      "\n",
      "     :: Query time: 3.96s\n",
      "ERROR PARSING CODE\n",
      "ERROR PARSING CODE\n",
      "     :: Evolution time: 13.49s\n",
      "üèÜ Best Code Performance Summary üèÜ\n",
      "  ‚ö° Structural fitness: 0.00\n",
      "  üéØ Functional fitness: 0.00\n",
      "  ‚≠ê Global fitness:     0.00\n",
      "  üîÑ Compiled solutions:        1\n",
      "  ‚è±Ô∏è Time breakdown:\n",
      "     :: Query time: 3.96s\n",
      "     :: Evolution time: 13.49s\n",
      "     :: Evaluation time: 1.08s\n",
      "     :: Total time: 18.54s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìä Code 0: Fitness: 0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "‚ùå Error Messages:\n",
      "object of type 'int' has no len()\n",
      "================================================================================\n",
      "\n",
      "Status code: 200\n",
      "Response text: {\"status\":\"success\"}\n"
     ]
    }
   ],
   "source": [
    "# Test on meta_api fuctionals\n",
    "from methods.meta_api import nodes_from_api\n",
    "api_name = \"langgraph\"\n",
    "doc_nodes, guide_nodes = nodes_from_api(api_name, fast_response=get_endpoint_response, slow_response=get_claude_response, max_links=5, view_on_frontend=True) # Takes 2 mins to scrape langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to get into this documentation instead for better scrawling\n",
    "# https://python.langchain.com/v0.1/docs/use_cases/web_scraping/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.2 s ¬± 0 ns per loop (mean ¬± std. dev. of 1 run, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 1\n",
    "import http\n",
    "import json\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import httpx\n",
    "\n",
    "api_name = \"langgraph\"\n",
    "\n",
    "def _search_google(query: str):\n",
    "    \"\"\"\n",
    "    Use Serper API to search Google for information\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: Parsed JSON response from the API\n",
    "    \"\"\"\n",
    "    conn = http.client.HTTPSConnection(\"google.serper.dev\")\n",
    "    payload = json.dumps({\"q\": query})\n",
    "    headers = {\n",
    "        \"X-API-KEY\": os.environ[\"SERPER_API_KEY\"],\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        conn.request(\"POST\", \"/search\", payload, headers)\n",
    "        res = conn.getresponse()\n",
    "        data = res.read()\n",
    "        return json.loads(data.decode(\"utf-8\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during API request: {str(e)}\")\n",
    "        return {}\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "def get_content(link):\n",
    "    res = httpx.get(link, follow_redirects=True)\n",
    "    res.raise_for_status()\n",
    "    url = str(res.url)\n",
    "\n",
    "    return res.text, url\n",
    "\n",
    "link = _search_google(f\"{api_name} python docs\")[\"organic\"][0][\"link\"]\n",
    "domain = urllib.parse.urlparse(link).netloc\n",
    "try:\n",
    "    content, url = get_content(link)\n",
    "except httpx.HTTPStatusError as e:\n",
    "    print(f\"Error occurred during request: {str(e)}\")\n",
    "\n",
    "htmls = [content]\n",
    "links = [url]\n",
    "ptr = 0\n",
    "while ptr < len(links):\n",
    "    soup = BeautifulSoup(htmls[ptr], \"html.parser\")\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"]\n",
    "        new_link = urllib.parse.urljoin(links[ptr], href.split(\"#\")[0])\n",
    "        parse = urllib.parse.urlparse(new_link)\n",
    "        if (\n",
    "            links[0] in new_link\n",
    "            and new_link not in links\n",
    "            and new_link + \"/\" not in links\n",
    "            and parse.scheme in [\"http\", \"https\"]\n",
    "        ):\n",
    "            try:\n",
    "                content, url = get_content(new_link)\n",
    "                htmls.append(content)\n",
    "                links.append(url)\n",
    "            except httpx.HTTPStatusError as e:\n",
    "                print(f\"Error occurred during request: {str(e)}\")\n",
    "    ptr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 32.10880398750305\n",
      "Number of webpages: 191\n",
      "Time taken: 31.19189691543579\n",
      "Number of webpages: 191\n",
      "Time taken: 32.00479292869568\n",
      "Number of webpages: 191\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import http\n",
    "import json\n",
    "import urllib\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import httpx\n",
    "api_name = \"langgraph\"\n",
    "for _ in range(3):\n",
    "    start_time = time.time()\n",
    "    client = httpx.AsyncClient(timeout=None)\n",
    "\n",
    "    def _search_google(query: str):\n",
    "        \"\"\"\n",
    "        Use Serper API to search Google for information\n",
    "\n",
    "        Args:\n",
    "            query (str): The search query\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: Parsed JSON response from the API\n",
    "        \"\"\"\n",
    "        conn = http.client.HTTPSConnection(\"google.serper.dev\")\n",
    "        payload = json.dumps({\"q\": query})\n",
    "        headers = {\n",
    "            \"X-API-KEY\": os.environ[\"SERPER_API_KEY\"],\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            conn.request(\"POST\", \"/search\", payload, headers)\n",
    "            res = conn.getresponse()\n",
    "            data = res.read()\n",
    "            return json.loads(data.decode(\"utf-8\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred during API request: {str(e)}\")\n",
    "            return {}\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "    async def aget_content(link, client):\n",
    "        res = await client.get(link, follow_redirects=True)\n",
    "        if res.status_code == 200:\n",
    "            url = str(res.url)\n",
    "            return res.text, url\n",
    "        else:\n",
    "            return \"\", \"\"\n",
    "\n",
    "    webpages = []\n",
    "    visit = set()\n",
    "\n",
    "    async def recursive_search(link, client, ref_url=None):\n",
    "        content, url = await aget_content(link, client)\n",
    "        if ref_url is None:\n",
    "            ref_url = url\n",
    "        if url and content:\n",
    "            webpages.append((url, content))\n",
    "            visit.add(url)\n",
    "        soup = BeautifulSoup(content, \"html.parser\")\n",
    "        new_links = []\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"]\n",
    "            new_link = urllib.parse.urljoin(link, href.split(\"#\")[0])\n",
    "            parse = urllib.parse.urlparse(new_link)\n",
    "            if (\n",
    "                ref_url in new_link\n",
    "                and new_link not in visit\n",
    "                and new_link + \"/\" not in visit\n",
    "                and parse.scheme in [\"http\", \"https\"]\n",
    "            ):\n",
    "                visit.add(new_link)\n",
    "                new_links.append(new_link)\n",
    "        await asyncio.gather(*[recursive_search(link, client, ref_url) for link in new_links])\n",
    "        \n",
    "\n",
    "    link = _search_google(f\"{api_name} python docs\")[\"organic\"][0][\"link\"]\n",
    "    domain = urllib.parse.urlparse(link).netloc\n",
    "\n",
    "    await recursive_search(link, client)\n",
    "\n",
    "    await client.aclose()\n",
    "    end = time.time()\n",
    "    print(f\"Time taken: {end - start_time}\")\n",
    "    print(f\"Number of webpages: {len(webpages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test case || evaluation || \n",
    "# - custom metric \n",
    "# - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
